{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Convolutional Auto-encoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import imutils\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import collections\n",
    "from collections import namedtuple, OrderedDict\n",
    "\n",
    "import typing\n",
    "from typing import List, Tuple, Union, Callable\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchsummary import summary\n",
    "\n",
    "from torch import nn\n",
    "from torch.nn import (Sequential,\n",
    "                      Module,\n",
    "                      Conv2d,\n",
    "                      ConvTranspose2d,\n",
    "                      Upsample,\n",
    "                      Linear,\n",
    "                      MaxPool2d,\n",
    "                      ReLU,\n",
    "                      Sigmoid,\n",
    "                      Flatten,\n",
    "                      Unflatten,\n",
    "                      LogSoftmax)\n",
    "\n",
    "import torchvision.datasets\n",
    "from torchvision.datasets import KMNIST\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Subset\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoderBase(Sequential):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(AutoEncoderBase, self).__init__(*args, **kwargs)\n",
    "    def get_k_out_shape(self,\n",
    "                        in_shape: Tuple[int,int,int], \n",
    "                        module: Union[Conv2d, MaxPool2d] = None, \n",
    "                        kernel: Union[Tuple[int,int], int] = None,\n",
    "                        stride: Union[Tuple[int,int], int] = None,\n",
    "                        padding: Union[Tuple[int,int], int] = None,\n",
    "                        out_channels: int = None,\n",
    "                        ) -> Tuple[int,int,int]:\n",
    "        # validate arguments.\n",
    "        if isinstance(module, (Conv2d, MaxPool2d)):\n",
    "            kernel = module.kernel_size\n",
    "            stride = module.stride\n",
    "            padding = module.padding\n",
    "            if isinstance(module, Conv2d): out_channels = module.out_channels\n",
    "        elif not all([isinstance(kernel, (tuple, int)), \n",
    "                    isinstance(stride, (tuple, int)), \n",
    "                    isinstance(padding, (tuple, int))]):\n",
    "            raise ValueError(\"Arguments kernel, stride and padding must be ints or tuples of ints.\")\n",
    "        # split into x,y axises.\n",
    "        if isinstance(kernel, int): kernel_y, kernel_x = kernel, kernel\n",
    "        else: kernel_y, kernel_x = kernel\n",
    "        if isinstance(stride, int): stride_y, stride_x = stride, stride\n",
    "        else: stride_y, stride_x = stride\n",
    "        if isinstance(padding, int): padding_y, padding_x = padding, padding\n",
    "        else: padding_y, padding_x = padding\n",
    "        # calculate dimensions.\n",
    "        h = int( np.ceil( (in_shape[1] + (padding_y*2) - (kernel_y-1) ) / stride_y ) )\n",
    "        w = int( np.ceil( (in_shape[2] + (padding_x*2) - (kernel_x-1) ) / stride_x ) )\n",
    "        if out_channels is None: out_channels = in_shape[0]\n",
    "        return out_channels, h, w\n",
    "    def init_x_shapes(self, \n",
    "                      image_shape: Tuple[int,int,int], \n",
    "                      init_channels: int, \n",
    "                      layer_depth: int, \n",
    "                      kernel_size: Union[Tuple[int,int], int],\n",
    "                      stride: Union[Tuple[int,int], int],\n",
    "                      padding: Union[Tuple[int,int], int],\n",
    "                      fully_connected: bool,\n",
    "                      latent_dim: int):\n",
    "        # determine all shapes throughout feeding forward.\n",
    "        x_shapes: List[Tuple[int,int,int]] = [image_shape, [init_channels,-1.-1]]\n",
    "        for _ in range(layer_depth):\n",
    "            x_shapes[-1] = self.get_k_out_shape(in_shape=x_shapes[-2], \n",
    "                                                 kernel=kernel_size, \n",
    "                                                 stride=stride, \n",
    "                                                 padding=padding, \n",
    "                                                 out_channels=x_shapes[-1][0])\n",
    "            x_shapes.append([x_shapes[-1][0], x_shapes[-1][1]//2, x_shapes[-1][2]//2])\n",
    "            x_shapes.append([x_shapes[-1][0]*2,-1,-1])\n",
    "        x_shapes.pop()\n",
    "        if fully_connected: x_shapes += [(np.prod(x_shapes[-1]),), (latent_dim,)]\n",
    "        self._x_shapes = x_shapes\n",
    "    @property\n",
    "    def x_shapes(self) -> list: return self._x_shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvLayer(Sequential):\n",
    "    def __init__(self, \n",
    "                 conv_in_channels: int, \n",
    "                 conv_out_channels: int, \n",
    "                 conv_kernel_size: Tuple[int,int] = (5,5),\n",
    "                 conv_stride: int = 1,\n",
    "                 conv_padding: int = 0,    \n",
    "                 pool_kernel_size: Tuple[int,int] = (2,2),\n",
    "                 pool_stride: int = (2,2),\n",
    "                 pool_padding: int = 0,\n",
    "                 activation_func: Module = ReLU,\n",
    "                 ) -> None:\n",
    "        super(ConvLayer, self).__init__(\n",
    "            Conv2d(in_channels=conv_in_channels, \n",
    "                   out_channels=conv_out_channels, \n",
    "                   kernel_size=conv_kernel_size, \n",
    "                   stride=conv_stride, \n",
    "                   padding=conv_padding), \n",
    "            activation_func(), \n",
    "            MaxPool2d(kernel_size=pool_kernel_size, \n",
    "                      stride=pool_stride, \n",
    "                      padding=pool_padding)\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(AutoEncoderBase):\n",
    "    def __init__(self, \n",
    "                image_shape: Tuple[int,int,int], \n",
    "                layer_depth: int,\n",
    "                latent_dim: int, \n",
    "                init_channels: int = 32,\n",
    "                conv_kernel_size: Tuple[int,int] = (5,5),\n",
    "                conv_stride: int = 1,\n",
    "                conv_padding: int = 0,    \n",
    "                pool_kernel_size: Tuple[int, int] = (2, 2),\n",
    "                pool_stride: int = (2, 2),\n",
    "                pool_padding: int = 0,\n",
    "                activation_func: Module = ReLU,\n",
    "                fully_connected: bool = True,\n",
    "                 ) -> None:\n",
    "        # determine all shapes throughout feeding forward.\n",
    "        self.init_x_shapes(image_shape=image_shape,\n",
    "                           init_channels=init_channels,\n",
    "                           layer_depth=layer_depth,\n",
    "                           kernel_size=conv_kernel_size,\n",
    "                           stride=conv_stride,\n",
    "                           padding=conv_padding,\n",
    "                           fully_connected=fully_connected,\n",
    "                           latent_dim=latent_dim)\n",
    "        # construct each layer.\n",
    "        encoder_layers: List[ConvLayer] = []\n",
    "        for i in range(layer_depth):\n",
    "            idx = i*2\n",
    "            encoder_layers.append(ConvLayer(\n",
    "                conv_in_channels=self.x_shapes[idx][0], \n",
    "                conv_out_channels=self.x_shapes[idx+1][0],\n",
    "                conv_kernel_size=conv_kernel_size,\n",
    "                conv_stride=conv_stride,\n",
    "                conv_padding=conv_padding,\n",
    "                pool_kernel_size= pool_kernel_size,\n",
    "                pool_stride=pool_stride,\n",
    "                pool_padding=pool_padding,\n",
    "                activation_func=activation_func))\n",
    "        # Fully connceted layer for flattening to latent.\n",
    "        if fully_connected: encoder_layers += [ Flatten(), Linear(in_features=self.x_shapes[-2][0], out_features=self.x_shapes[-1][0]) ]\n",
    "        # Sequential.\n",
    "        super(Encoder, self).__init__(*encoder_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TConvLayer(Sequential):\n",
    "    def __init__(self, \n",
    "                 upsample_size: Tuple[int,int],\n",
    "                 tconv_in_channels: int, \n",
    "                 tconv_out_channels: int, \n",
    "                 tconv_kernel_size: Tuple[int,int] = (5,5),\n",
    "                 tconv_stride: int = 1,\n",
    "                 tconv_padding: int = 0,\n",
    "                 activation_func: Module = ReLU,\n",
    "                 ) -> None:\n",
    "        super(TConvLayer, self).__init__(\n",
    "            Upsample(size=upsample_size),\n",
    "            ConvTranspose2d(in_channels=tconv_in_channels, \n",
    "                            out_channels=tconv_out_channels, \n",
    "                            kernel_size=tconv_kernel_size, \n",
    "                            stride=tconv_stride, \n",
    "                            padding=tconv_padding),\n",
    "            activation_func(),\n",
    "            )        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(AutoEncoderBase):\n",
    "    def __init__(self, \n",
    "                 image_shape: Tuple[int,int,int], \n",
    "                 layer_depth: int,\n",
    "                 latent_dim: int, \n",
    "                 kernel_size: Tuple[int,int] = (5,5),\n",
    "                 stride: int = 1,\n",
    "                 padding: int = 0,    \n",
    "                 init_channels: int = 32,\n",
    "                 activation_func: Callable = ReLU,\n",
    "                 out_act_func: Callable = Sigmoid,\n",
    "                 fully_connected: bool = True,\n",
    "                 ) -> None:\n",
    "        # determine all shapes throughout feeding forward.\n",
    "        self.init_x_shapes(image_shape=image_shape,\n",
    "                           init_channels=init_channels,\n",
    "                           layer_depth=layer_depth,\n",
    "                           kernel_size=kernel_size,\n",
    "                           stride=stride,\n",
    "                           padding=padding,\n",
    "                           fully_connected=fully_connected,\n",
    "                           latent_dim=latent_dim)\n",
    "        self._x_shapes.reverse()\n",
    "        # fully connected layer for unflattening from latent.\n",
    "        decoder_layers = [ Linear(in_features=self.x_shapes[0][0], out_features=self.x_shapes[1][0]), Unflatten(1, self.x_shapes[2]) ]\n",
    "        # construct each layer\n",
    "        for i in range(layer_depth):\n",
    "            idx = (i*2)+3\n",
    "            decoder_layers.append(TConvLayer(\n",
    "                upsample_size=self.x_shapes[idx][1:],\n",
    "                tconv_in_channels=self.x_shapes[idx][0],\n",
    "                tconv_out_channels=self.x_shapes[idx+1][0],\n",
    "                tconv_kernel_size=kernel_size,\n",
    "                tconv_stride=stride,\n",
    "                tconv_padding=padding,\n",
    "                activation_func=out_act_func if i+1 == layer_depth else activation_func\n",
    "            ))\n",
    "        # Sequential.\n",
    "        super(Decoder, self).__init__(*decoder_layers)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(Sequential):\n",
    "    def __init__(self,\n",
    "                image_shape: Tuple[int, int, int],\n",
    "                layer_depth: int,\n",
    "                latent_dim: int,\n",
    "                init_channels: int = 32,\n",
    "                conv_kernel: Tuple[int, int] = (5, 5),\n",
    "                conv_stride: int = 1,\n",
    "                conv_padding: int = 0,\n",
    "                pool_kernel: Tuple[int, int] = (2, 2),\n",
    "                pool_stride: int = (2, 2),\n",
    "                pool_padding: int = 0,\n",
    "                conv_act_func: Module = ReLU,\n",
    "                tconv_kernel: Tuple[int, int] = (5, 5),\n",
    "                tconv_stride: int = 1,\n",
    "                tconv_padding: int = 0,\n",
    "                tconv_act_func: Callable = ReLU,\n",
    "                out_act_func: Callable = Sigmoid,\n",
    "                fully_connected: bool = True\n",
    "    ):\n",
    "        super(AutoEncoder, self).__init__(\n",
    "            Encoder(image_shape=image_shape, \n",
    "                    layer_depth=layer_depth, latent_dim=latent_dim,\n",
    "                    init_channels=init_channels,\n",
    "                    conv_kernel_size=conv_kernel,\n",
    "                    conv_stride=conv_stride,\n",
    "                    conv_padding=conv_padding,\n",
    "                    pool_kernel_size=pool_kernel,\n",
    "                    pool_stride=pool_stride,\n",
    "                    pool_padding=pool_padding,\n",
    "                    activation_func=conv_act_func,\n",
    "                    fully_connected=fully_connected), \n",
    "            Decoder(image_shape=image_shape, \n",
    "                    layer_depth=layer_depth, \n",
    "                    latent_dim=latent_dim,\n",
    "                    kernel_size=tconv_kernel,\n",
    "                    stride=tconv_stride,\n",
    "                    padding=tconv_padding,\n",
    "                    init_channels=init_channels,\n",
    "                    activation_func=tconv_act_func,\n",
    "                    out_act_func=out_act_func,\n",
    "                    fully_connected=fully_connected)\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_shape = (1,50,50)\n",
    "layer_depth = 3\n",
    "latent_dim = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 46, 46]             832\n",
      "              ReLU-2           [-1, 32, 46, 46]               0\n",
      "         MaxPool2d-3           [-1, 32, 23, 23]               0\n",
      "            Conv2d-4           [-1, 64, 19, 19]          51,264\n",
      "              ReLU-5           [-1, 64, 19, 19]               0\n",
      "         MaxPool2d-6             [-1, 64, 9, 9]               0\n",
      "            Conv2d-7            [-1, 128, 5, 5]         204,928\n",
      "              ReLU-8            [-1, 128, 5, 5]               0\n",
      "         MaxPool2d-9            [-1, 128, 2, 2]               0\n",
      "          Flatten-10                  [-1, 512]               0\n",
      "           Linear-11                  [-1, 128]          65,664\n",
      "           Linear-12                  [-1, 512]          66,048\n",
      "        Unflatten-13            [-1, 128, 2, 2]               0\n",
      "         Upsample-14            [-1, 128, 5, 5]               0\n",
      "  ConvTranspose2d-15             [-1, 64, 9, 9]         204,864\n",
      "             ReLU-16             [-1, 64, 9, 9]               0\n",
      "         Upsample-17           [-1, 64, 19, 19]               0\n",
      "  ConvTranspose2d-18           [-1, 32, 23, 23]          51,232\n",
      "             ReLU-19           [-1, 32, 23, 23]               0\n",
      "         Upsample-20           [-1, 32, 46, 46]               0\n",
      "  ConvTranspose2d-21            [-1, 1, 50, 50]             801\n",
      "          Sigmoid-22            [-1, 1, 50, 50]               0\n",
      "================================================================\n",
      "Total params: 645,633\n",
      "Trainable params: 645,633\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 2.71\n",
      "Params size (MB): 2.46\n",
      "Estimated Total Size (MB): 5.19\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "ae_model = AutoEncoder(image_shape=image_shape,\n",
    "                       layer_depth=layer_depth,\n",
    "                       latent_dim=latent_dim)\n",
    "ae_stat = summary(ae_model, image_shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "basex",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
